{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [16/Dec/2020 17:58:40] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from flask import Flask, request, jsonify, render_template, url_for\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from datetime import timedelta  \n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Define class function\n",
    "class MultiColumnLabelEncoder:\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.encoders = {}\n",
    "        columns = X.columns if self.columns is None else self.columns\n",
    "        for col in columns:\n",
    "            self.encoders[col] = LabelEncoder().fit(X[col])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        output = X.copy()\n",
    "        columns = X.columns if self.columns is None else self.columns\n",
    "        for col in columns:\n",
    "            output[col] = self.encoders[col].transform(X[col])\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X,y).transform(X)\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        output = X.copy()\n",
    "        columns = X.columns if self.columns is None else self.columns\n",
    "        for col in columns:\n",
    "            output[col] = self.encoders[col].inverse_transform(X[col])\n",
    "        return output\n",
    "    \n",
    "# feature engineering for previous month average, maximum and minimum\n",
    "def mth_avg (n):\n",
    "    mth_avg = df.groupby(['Year','Month','distributor_name','customer_name','product_name'])['total_qty'].mean().reset_index()\n",
    "    mth_avg = mth_avg.rename(columns={'total_qty':'mth%s_avg_qty' %n})\n",
    "    mth_avg['Month'] = mth_avg['Month']+n\n",
    "    mth_avg.loc[mth_avg.Month == (12+n), 'Year'] = mth_avg.loc[mth_avg.Month == (12 + n)].Year + 1 \n",
    "    mth_avg['Month'] = mth_avg['Month'].replace((12+n), n)\n",
    "    mth_avg['mth%s_key' %n] = mth_avg['Year'].map(str) + mth_avg['Month'].map(str) + mth_avg['distributor_name'].map(str) + mth_avg['customer_name'].map(str) + mth_avg['product_name'].map(str)\n",
    "    mth_avg = mth_avg.drop(['Year','Month','distributor_name','customer_name','product_name'], axis=1)\n",
    "    return mth_avg\n",
    "\n",
    "def mth_max(n):\n",
    "    mth_max = df.groupby(['Year','Month','distributor_name','customer_name','product_name'])['total_qty'].max().reset_index()\n",
    "    mth_max = mth_max.rename(columns={'total_qty':'mth%s_max_qty' %n})\n",
    "    mth_max['Month'] = mth_max['Month']+n\n",
    "    mth_max.loc[mth_max.Month == (12+n), 'Year'] = mth_max.loc[mth_max.Month == (12+n)].Year + 1 \n",
    "    mth_max['Month'] = mth_max['Month'].replace((12+n), n)\n",
    "    mth_max['mth%s_key' %n] = mth_max['Year'].map(str) + mth_max['Month'].map(str) + mth_max['distributor_name'].map(str) + mth_max['customer_name'].map(str) + mth_max['product_name'].map(str)\n",
    "    mth_max = mth_max.drop(['Year','Month','distributor_name','customer_name','product_name'], axis=1)\n",
    "    return mth_max\n",
    "\n",
    "def mth_min(n):\n",
    "    mth_min = df.groupby(['Year','Month','distributor_name','customer_name','product_name'])['total_qty'].min().reset_index()\n",
    "    mth_min = mth_min.rename(columns={'total_qty':'mth%s_min_qty' %n})\n",
    "    mth_min['Month'] = mth_min['Month']+n\n",
    "    mth_min.loc[mth_min.Month == (12+n), 'Year'] = mth_min.loc[mth_min.Month == (12+n)].Year + 1 \n",
    "    mth_min['Month'] = mth_min['Month'].replace((12+n), n)\n",
    "    mth_min['mth%s_key' %n] = mth_min['Year'].map(str) + mth_min['Month'].map(str) + mth_min['distributor_name'].map(str) + mth_min['customer_name'].map(str) + mth_min['product_name'].map(str)\n",
    "    mth_min = mth_min.drop(['Year','Month','distributor_name','customer_name','product_name'], axis=1)\n",
    "    return mth_min\n",
    "\n",
    "# merge into one dataframe\n",
    "def mth(n):\n",
    "    global df\n",
    "    mth = pd.merge(mth_avg(n), mth_max(n), how='left', on=('mth%s_key'%n))\n",
    "    mth = pd.merge(mth, mth_min(n), how='left', on=('mth%s_key'%n))\n",
    "    df['mth%s_key' %n] = df['Year'].map(str) + df['Month'].map(str) + df['distributor_name'].map(str) + df['customer_name'].map(str) + df['product_name'].map(str)\n",
    "    # merge with df\n",
    "    df = pd.merge(df, mth, how='left', on=('mth%s_key' %n))\n",
    "    df['mth%s_avg_qty'%n] = df['mth%s_avg_qty'%n].fillna(0)\n",
    "    df['mth%s_max_qty'%n] = df['mth%s_max_qty'%n].fillna(0)\n",
    "    df['mth%s_min_qty'%n] = df['mth%s_min_qty'%n].fillna(0)\n",
    "    return df\n",
    "\n",
    "# feature engineering for last year month average, maximum and minimum\n",
    "def last_yr_mth_avg(n):\n",
    "    last_yr_mth_avg = df.groupby(['Year','Month','distributor_name','customer_name','product_name'])['total_qty'].mean().reset_index()\n",
    "    last_yr_mth_avg = last_yr_mth_avg.rename(columns={'total_qty':'last_yr%s_mth_avg_qty'%n})\n",
    "    last_yr_mth_avg['Year'] = last_yr_mth_avg['Year']+n\n",
    "    last_yr_mth_avg['last_yr%s_mth_key'%n] = last_yr_mth_avg['Year'].map(str) + last_yr_mth_avg['Month'].map(str) + last_yr_mth_avg['distributor_name'].map(str) + last_yr_mth_avg['customer_name'].map(str) + last_yr_mth_avg['product_name'].map(str)\n",
    "    last_yr_mth_avg = last_yr_mth_avg.drop(['Year','Month','distributor_name','customer_name','product_name'], axis=1)\n",
    "    return last_yr_mth_avg\n",
    "\n",
    "def last_yr_mth_max(n):\n",
    "    last_yr_mth_max = df.groupby(['Year','Month','distributor_name','customer_name','product_name'])['total_qty'].max().reset_index()\n",
    "    last_yr_mth_max = last_yr_mth_max.rename(columns={'total_qty':'last_yr%s_mth_max_qty'%n})\n",
    "    last_yr_mth_max['Year'] = last_yr_mth_max['Year']+n\n",
    "    last_yr_mth_max['last_yr%s_mth_key'%n] = last_yr_mth_max['Year'].map(str) + last_yr_mth_max['Month'].map(str) + last_yr_mth_max['distributor_name'].map(str) + last_yr_mth_max['customer_name'].map(str) + last_yr_mth_max['product_name'].map(str)\n",
    "    last_yr_mth_max = last_yr_mth_max.drop(['Year','Month','distributor_name','customer_name','product_name'], axis=1)   \n",
    "    return last_yr_mth_max\n",
    "\n",
    "def last_yr_mth_min(n):\n",
    "    last_yr_mth_min = df.groupby(['Year','Month','distributor_name','customer_name','product_name'])['total_qty'].min().reset_index()\n",
    "    last_yr_mth_min = last_yr_mth_min.rename(columns={'total_qty':'last_yr%s_mth_min_qty'%n})\n",
    "    last_yr_mth_min['Year'] = last_yr_mth_min['Year']+n\n",
    "    last_yr_mth_min['last_yr%s_mth_key'%n] = last_yr_mth_min['Year'].map(str) + last_yr_mth_min['Month'].map(str) + last_yr_mth_min['distributor_name'].map(str) + last_yr_mth_min['customer_name'].map(str) + last_yr_mth_min['product_name'].map(str)\n",
    "    last_yr_mth_min = last_yr_mth_min.drop(['Year','Month','distributor_name','customer_name','product_name'], axis=1)\n",
    "    return last_yr_mth_min\n",
    "\n",
    "def last_yr_mth(n):\n",
    "    # merge into one dataframe\n",
    "    global df\n",
    "    last_yr_mth = pd.merge(last_yr_mth_avg(n), last_yr_mth_max(n), how='left', on=('last_yr%s_mth_key'%n))\n",
    "    last_yr_mth = pd.merge(last_yr_mth, last_yr_mth_min(n), how='left', on=('last_yr%s_mth_key'%n))\n",
    "    df['last_yr%s_mth_key'%n] = df['Year'].map(str) + df['Month'].map(str) + df['distributor_name'].map(str) + df['customer_name'].map(str) + df['product_name'].map(str)\n",
    "    # merge with df\n",
    "    df = pd.merge(df, last_yr_mth, how='left', on=('last_yr%s_mth_key'%n))\n",
    "    df['last_yr%s_mth_avg_qty'%n] = df['last_yr%s_mth_avg_qty'%n].fillna(0)\n",
    "    df['last_yr%s_mth_max_qty'%n] = df['last_yr%s_mth_max_qty'%n].fillna(0)\n",
    "    df['last_yr%s_mth_min_qty'%n] = df['last_yr%s_mth_min_qty'%n].fillna(0)\n",
    "    return df\n",
    "\n",
    "#week\n",
    "def week_avg(n):\n",
    "    week_avg = df.groupby(['ww','distributor_name','customer_name','product_name'])['total_qty'].mean().reset_index()\n",
    "    week_avg = week_avg.rename(columns={'total_qty':'week%s_avg_qty' %n})\n",
    "    week_avg['week%s_key'%n] = week_avg['ww'].map(str) + week_avg['distributor_name'].map(str) + week_avg['customer_name'].map(str) + week_avg['product_name'].map(str)\n",
    "    week_avg = week_avg.drop(['ww','distributor_name','customer_name','product_name'], axis=1)\n",
    "    return week_avg\n",
    "\n",
    "def week_max(n):\n",
    "    week_max = df.groupby(['ww','distributor_name','customer_name','product_name'])['total_qty'].max().reset_index()\n",
    "    week_max = week_max.rename(columns={'total_qty':'week%s_max_qty' %n})\n",
    "    week_max['week%s_key'%n] = week_max['ww'].map(str) + week_max['distributor_name'].map(str) + week_max['customer_name'].map(str) + week_max['product_name'].map(str)\n",
    "    week_max = week_max.drop(['ww','distributor_name','customer_name','product_name'], axis=1)\n",
    "    return week_max\n",
    "\n",
    "def week_min(n):  \n",
    "    week_min = df.groupby(['ww','distributor_name','customer_name','product_name'])['total_qty'].min().reset_index()\n",
    "    week_min = week_min.rename(columns={'total_qty':'week%s_min_qty' %n})\n",
    "    week_min['week%s_key'%n] = week_min['ww'].map(str) + week_min['distributor_name'].map(str) + week_min['customer_name'].map(str) + week_min['product_name'].map(str)\n",
    "    week_min = week_min.drop(['ww','distributor_name','customer_name','product_name'], axis=1)\n",
    "    return week_min\n",
    "\n",
    "def week(n):\n",
    "    # merge into one dataframe\n",
    "    global df\n",
    "    week = pd.merge(week_avg(n), week_max(n), how='left', on=('week%s_key'%n))\n",
    "    week = pd.merge(week, week_min(n), how='left', on=('week%s_key'%n))\n",
    "    df['week%s'%n] = (df['txn_date']-timedelta(weeks = n)).dt.strftime('%G%V').astype(int)\n",
    "    df['week%s_key'%n] = df['week%s'%n].map(str) + df['distributor_name'].map(str) + df['customer_name'].map(str) + df['product_name'].map(str)\n",
    "    # merge with df\n",
    "    df = pd.merge(df, week, how='left', on=('week%s_key'%n))\n",
    "    df['week%s_avg_qty'%n] = df['week%s_avg_qty'%n].fillna(0)\n",
    "    df['week%s_max_qty'%n] = df['week%s_max_qty'%n].fillna(0)\n",
    "    df['week%s_min_qty'%n] = df['week%s_min_qty'%n].fillna(0)\n",
    "    return df\n",
    "\n",
    "#weeklag\n",
    "def weeklag(n):\n",
    "    # feature engineering for previous week lag \n",
    "    global df\n",
    "    weeklag = df.groupby(['ww','dayofweek','distributor_name','customer_name','product_name'])['total_qty'].sum().reset_index()\n",
    "    weeklag = weeklag.rename(columns={'total_qty':'weeklag%s_qty'%n})\n",
    "    weeklag['weeklag%s_key'%n] = weeklag['ww'].map(str) + weeklag['dayofweek'].map(str) + weeklag['distributor_name'].map(str) + weeklag['customer_name'].map(str) + weeklag['product_name'].map(str)\n",
    "    # drop extra columns\n",
    "    weeklag = weeklag.drop(['ww','dayofweek','distributor_name','customer_name','product_name'], axis=1)\n",
    "    df['weeklag%s_key'%n] = df['week%s'%n].map(str) + df['dayofweek'].map(str) + df['distributor_name'].map(str) + df['customer_name'].map(str) + df['product_name'].map(str)\n",
    "    # merge with df\n",
    "    df = pd.merge(df, weeklag, how='left', on=('weeklag%s_key'%n))\n",
    "    df['weeklag%s_qty'%n] = df['weeklag%s_qty'%n].fillna(0)\n",
    "    return df\n",
    "\n",
    "# feature engineering for previous year1 average, maximum and minimum\n",
    "def year_avg(n):\n",
    "    year_avg = df.groupby(['Year','distributor_name','customer_name','product_name'])['total_qty'].mean().reset_index()\n",
    "    year_avg = year_avg.rename(columns={'total_qty':'year%s_avg_qty' %n})\n",
    "    year_avg['Year'] = year_avg['Year']+n\n",
    "    year_avg['year%s_key'%n] = year_avg['Year'].map(str) + year_avg['distributor_name'].map(str) + year_avg['customer_name'].map(str) + year_avg['product_name'].map(str)\n",
    "    year_avg = year_avg.drop(['Year','distributor_name','customer_name','product_name'], axis=1)\n",
    "    return year_avg\n",
    "\n",
    "def year_max(n):\n",
    "    year_max = df.groupby(['Year','distributor_name','customer_name','product_name'])['total_qty'].max().reset_index()\n",
    "    year_max = year_max.rename(columns={'total_qty':'year%s_max_qty' %n})\n",
    "    year_max['Year'] = year_max['Year']+n\n",
    "    year_max['year%s_key'%n] = year_max['Year'].map(str) + year_max['distributor_name'].map(str) + year_max['customer_name'].map(str) + year_max['product_name'].map(str)\n",
    "    year_max = year_max.drop(['Year','distributor_name','customer_name','product_name'], axis=1)\n",
    "    return year_max\n",
    "\n",
    "def year_min(n):\n",
    "    year_min = df.groupby(['Year','distributor_name','customer_name','product_name'])['total_qty'].min().reset_index()\n",
    "    year_min = year_min.rename(columns={'total_qty':'year%s_min_qty' %n})\n",
    "    year_min['Year'] = year_min['Year']+n\n",
    "    year_min['year%s_key'%n] = year_min['Year'].map(str) + year_min['distributor_name'].map(str) + year_min['customer_name'].map(str) + year_min['product_name'].map(str)\n",
    "    year_min = year_min.drop(['Year','distributor_name','customer_name','product_name'], axis=1)\n",
    "    return year_min\n",
    "\n",
    "def year(n):\n",
    "    # merge into one dataframe\n",
    "    global df\n",
    "    year = pd.merge(year_avg(n), year_max(n), how='left', on=('year%s_key'%n))\n",
    "    year = pd.merge(year, year_min(n), how='left', on=('year%s_key'%n))\n",
    "    df['year%s_key'%n] = df['Year'].map(str) + df['distributor_name'].map(str) + df['customer_name'].map(str) + df['product_name'].map(str)\n",
    "    # merge with df\n",
    "    df = pd.merge(df, year, how='left', on=('year%s_key'%n))\n",
    "    df['year%s_avg_qty'%n] = df['year%s_avg_qty'%n].fillna(0)\n",
    "    df['year%s_max_qty'%n] = df['year%s_max_qty'%n].fillna(0)\n",
    "    df['year%s_min_qty'%n] = df['year%s_min_qty'%n].fillna(0)\n",
    "    return df\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# create flask application instance\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the pipeline (MultiColumnLabelEncoder,model)\n",
    "modelPipeline=joblib.load('modelPipeline.pkl')\n",
    "\n",
    "# Read csv\n",
    "df = pd.read_csv(\"pivot.csv\", quotechar='\"',parse_dates=['txn_date'])\n",
    "\n",
    "#Convert function return value into an HTTP response to be displayed by main url ('/')\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('home.html')\n",
    "    \n",
    "#Convert function return value into an HTTP response to be displayed by url ('/predict') after receiving post request\n",
    "@app.route('/predict',methods = ['POST'])\n",
    "def predict():\n",
    "    global df\n",
    "    #Load data\n",
    "    int_features = [str(x) for x in request.form.values()]\n",
    "    int_features[0]=np.datetime64(int_features[0])\n",
    "    int2_features = [np.array(int_features)]\n",
    "    a=pd.DataFrame(int2_features,columns=['txn_date','distributor_name','customer_name','product_name'])\n",
    "    df=pd.concat([df, a], ignore_index=True)\n",
    "    \n",
    "    #Feature generation\n",
    "    df['ww'] = df['txn_date'].dt.strftime('%G%V').astype(int)\n",
    "    df['Year'] = df['txn_date'].dt.year\n",
    "    df['Month'] = df['txn_date'].dt.month\n",
    "    df['dayofweek'] = df['txn_date'].dt.dayofweek\n",
    "    \n",
    "    for x in range(1, 4):\n",
    "        df = mth(x)\n",
    "        df = last_yr_mth(x)\n",
    "        df = week(x)\n",
    "        df = weeklag(x)\n",
    "        df = year(x)   \n",
    "\n",
    "    # drop extra columns\n",
    "    df = df.drop(['txn_date','mth1_key','mth2_key','mth3_key','last_yr1_mth_key','last_yr2_mth_key','last_yr3_mth_key','week1','week2','week3','week1_key','week2_key','week3_key','weeklag1_key','weeklag2_key','weeklag3_key','year1_key','year2_key','year3_key'], axis=1)\n",
    "    \n",
    "   \n",
    "    categorical_variables = list(df.select_dtypes(['object']).columns)\n",
    "    for var in categorical_variables:\n",
    "        df[var] = df[var].astype(str)\n",
    "    \n",
    "    # split data\n",
    "    test = df.tail(len(a))\n",
    "    X_test = test.drop(['total_qty'],1)\n",
    "    y_test = test.total_qty\n",
    "    \n",
    "    # Predict \n",
    "    y_pred = modelPipeline.predict(X_test)\n",
    "    \n",
    "    # Sum up predicted sales in different levels \n",
    "    test['pred']=y_pred\n",
    "    m = test.groupby(['Year','Month','distributor_name','customer_name','product_name'])['pred'].sum().reset_index()\n",
    "    m_monthly = test.groupby(['Year','Month'])['total_qty','pred'].sum().reset_index()\n",
    "    m_distributor = test.groupby(['Year','Month','distributor_name'])['pred'].sum().reset_index()\n",
    "    m_distributor_customer = test.groupby(['Year','Month','distributor_name','customer_name'])['pred'].sum().reset_index()\n",
    "    m_product = test.groupby(['Year','Month','product_name'])['pred'].sum().reset_index()\n",
    "    \n",
    "    # check the prediction value using console\n",
    "    print(m.pred[0])\n",
    "    print(m_monthly.pred[0])\n",
    "    print(m_distributor.pred[0])\n",
    "    print(m_distributor_customer.pred[0])\n",
    "    print(m_product.pred[0])\n",
    "    print(X_test)\n",
    "    \n",
    "    return render_template('result.html', prediction_text=\"Monthly Sales Prediction is {:.2f}\".format(m_monthly.pred[0]),\n",
    "                           prediction_text1=\"Monthly distributor Sales Prediction is {:.2f}\".format(m_distributor.pred[0]),\n",
    "                           prediction_text2=\"Monthly customer Sales Prediction is {:.2f}\".format(m_distributor_customer.pred[0]),\n",
    "                           prediction_text3=\"Monthly Product Sales Prediction is {:.2f}\".format (m_product.pred[0]))\n",
    "\n",
    "#run the app\n",
    "if __name__ == '__main__':\n",
    "    #app.run(debug=True)\n",
    "    app.run(threaded=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
